# ğŸ¤– AI Learning Q&A Bot

An intelligent chatbot designed to help beginner and intermediate programmers learn Artificial Intelligence, Python, and Machine Learning. It uses a custom Q&A dataset, a fine-tuned quantized LLM, and Retrieval-Augmented Generation (RAG) to deliver concise and accurate responses. Runs locally using Ollama with optional LangChain and Streamlit integration.

---

## ğŸ“š Features

- ğŸ’¬ Ask AI/ML questions and get accurate, beginner-friendly answers.
- ğŸ“ Retrieval-Augmented Generation (RAG) for knowledge-grounded responses.
- ğŸ§  Fine-tuned lightweight LLM (`Phi-3 Mini 4-bit`) using the Unsloth library.
- ğŸ” Custom curated dataset with 100+ educational Q&A pairs.
- ğŸ§± Deployable with Ollama for fast, local inference.
- ğŸŒ Optional web UI using Streamlit and LangChain for interactive exploration.

---

## ğŸ› ï¸ Tech Stack

| Category            | Tools Used                                          |
|---------------------|-----------------------------------------------------|
| ğŸ’¡ Model            | Phi-3 Mini 4-bit (bnb)                             |
| ğŸ§ª Fine-Tuning      | Unsloth, PEFT, LoRA, HuggingFace Datasets          |
| ğŸ’¾ Quantization     | bitsandbytes, 4-bit GGUF export                    |
| ğŸ§  Deployment       | Ollama (for local model hosting)                   |
| ğŸ” RAG Components   | LangChain, ChromaDB                                |
| ğŸŒ Frontend (optional) | Streamlit (for chat interface)                  |
| ğŸ“ Dataset          | JSON file with 100+ AI/ML beginner Q&A pairs       |
| ğŸš€ Training Infra   | Google Colab with CUDA GPU support                 |

---

## ğŸ“ Project Structure

ai-learning-qa-bot/
â”œâ”€â”€ json_extraction_dataset_500.json   # Your training Q&A dataset
â”œâ”€â”€ fine_tune_colab.ipynb              # Fine-tuning script in Colab
â”œâ”€â”€ gguf_model/                        # Exported 4-bit GGUF model for Ollama
â”œâ”€â”€ ModelFile                          # Ollama model configuration
â”œâ”€â”€ app.py                             # (Optional) Streamlit app for chatbot UI
â””â”€â”€ README.md                          # This file

---

## ğŸ§ª How It Works

1. Fine-tuning: A 4-bit quantized Phi-3 model is fine-tuned on your curated Q&A dataset using LoRA adapters.
2. Export: The fine-tuned model is exported to GGUF format.
3. Ollama Setup: Model is loaded using an Ollama Modelfile with prompt templates and inference parameters.
4. Querying: You can ask questions via command line (Ollama) or through a web UI (Streamlit).
5. (Optional): Use LangChain + ChromaDB for RAG-based long context retrieval.

---

## ğŸ”§ Installation & Setup

### 1. Fine-Tune Model (Colab)
Open `fine_tune_colab.ipynb` and run all cells to:
- Load model
- Prepare dataset
- Fine-tune using Unsloth
- Export to GGUF for Ollama

### 2. Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

### 3. Create `Modelfile`
Use the following:

FROM ./unsloth.Q4_K_M.gguf

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER stop "<|end_of_text|>"
PARAMETER stop "<|user|>"

TEMPLATE """<|user|>
{{ .Prompt }}<|assistant|>
"""

SYSTEM """You are a helpful AI assistant specialized in AI and programming education."""

### 4. Run Model
ollama create aiqa -f Modelfile
ollama run aiqa

---

## ğŸŒ (Optional) Run Streamlit Chat UI

Install dependencies:
pip install streamlit langchain chromadb

Run app:
streamlit run app.py

---

## ğŸ§  Example Prompt

User: What is overfitting in machine learning?
Bot: Overfitting is when a model learns the training data too well, including its noise, and performs poorly on unseen data.

---

## ğŸ“Œ Notes

- Trained on 100 curated AI/ML beginner questions
- Works offline, lightweight for laptops
- Easily expandable to new topics by adding new Q&A data

---

## ğŸ“œ License

MIT License â€“ free to use and modify.

---

## ğŸ‘¨â€ğŸ’» Author

Created by Yusuf Bolat â€“ ChatGPT-assisted project.
